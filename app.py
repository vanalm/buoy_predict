# from flask import Flask, request, jsonify# import pandas as pd# # Import other necessary libraries and modules# from utils import *# import logging# logging.basicConfig(level=logging.DEBUG)# app = Flask(__name__)# @app.route('/predict', methods=['GET', 'POST'])# def predict():#     try:#         #fetch raw buoy data#         dfs = get_buoys(buoy_ids)        #         #begin cleaning data#         prepped_dfs = prep_dfs(dfs, cols_to_keep)        #         #merge and clean data#         dfx = get_merged(prepped_dfs)#         #get time of prediction#         time_of_y = get_future_time(dfx, lead_time)        #         dfx = convert_columns_to_float(dfx)#         #load scalers from file#         Xscaler, yscaler = load_scalers()#         #make columns align with the scaler#         dfx.columns = scaler_compatible_columns   #         #scale numberic, enocode cats     #         dfx_processed = encodeNscale(dfx, Xscaler)#         #making sure that all dummies are present for poper array shape#         dfx_processed_aligned = align_dataframes(dfx_processed, final_X_columns)#         #smoothing data for better prediction (as verified in previous experiments)#         dfx_processed__aligned_smoothed = smooth_dataframe(dfx_processed_aligned)#         print(f'shape of dfx is {dfx_processed__aligned_smoothed.shape}')#         #create X array#         X = get_data_contiguous_X_only(dfx_processed__aligned_smoothed, n_timesteps, lead_time=lead_time, num_outputs = num_outputs, timestep_size=3600)#         #load model#         model = load_model(model_name)#         #get raw prediction#         y_scaled = model.predict(X)#         #scale prediction#         y = yscaler.inverse_transform(y_scaled)#         print(f'HERE IS Y: {y}')#         prediction_list = y.tolist()#         # prediction_time_list = datetime_to_list(time_of_y)#         prediction_time_str = datetime_to_readable_string(time_of_y)    #         # Format and return the response#         return jsonify({#                 'prediction': prediction_list,#                 'prediction_time': prediction_time_str#             })#     except Exception as e:#         print(f'encountered an error: {e}')# if __name__ == "__main__":#     app.run(host='0.0.0.0', port=5000)from flask import Flask, request, jsonifyimport pandas as pdfrom utils import *  # Make sure utils.py is properly formatted and all necessary functions are definedimport loggingfrom tensorflow.keras.models import load_modelmodel_name = 'buoy_LSTM_6hrlead,16tsinput.h5'# Setup logginglogging.basicConfig(level=logging.DEBUG)logger = logging.getLogger()app = Flask(__name__)@app.route('/predict', methods=['GET', 'POST'])def predict():    try:        logger.info("Starting prediction process...")        # Fetch raw buoy data        logger.info("Fetching buoy data...")        dfs = get_buoys(buoy_ids)                # Begin cleaning data        logger.info("Preparing data...")        prepped_dfs = prep_dfs(dfs, cols_to_keep)                # Merge and clean data        logger.info("Merging data...")        dfx = get_merged(prepped_dfs)        # Get time of prediction        logger.info("Getting time of prediction...")        time_of_y = get_future_time(dfx, lead_time)                # Convert columns to float        logger.info("Converting columns to float...")        dfx = convert_columns_to_float(dfx)        # Load scalers from file        logger.info("Loading scalers...")        Xscaler, yscaler = load_scalers()        # Align columns with the scaler        dfx.columns = scaler_compatible_columns           # Scale numeric, encode categories        logger.info("Processing data...")        dfx_processed = encodeNscale(dfx, Xscaler)        # Ensure all dummies are present for proper array shape        dfx_processed_aligned = align_dataframes(dfx_processed, final_X_columns)        # Smoothing data for better prediction        logger.info("Smoothing data...")        dfx_processed__aligned_smoothed = smooth_dataframe(dfx_processed_aligned)        logger.info(f'Shape of dfx is {dfx_processed__aligned_smoothed.shape}')        # Create X array        logger.info("Creating input array...")        X = get_data_contiguous_X_only(dfx_processed__aligned_smoothed, n_timesteps, lead_time=lead_time, num_outputs=num_outputs, timestep_size=3600)        # Load model        logger.info("Loading model...")        model = load_model(model_name)        # Get raw prediction        logger.info("Making prediction...")        y_scaled = model.predict(X)        # Scale prediction        y = yscaler.inverse_transform(y_scaled)        logger.info(f'Prediction: {y}')        prediction_list = y.tolist()        prediction_time_str = datetime_to_readable_string(time_of_y)        # Format and return the response        return jsonify({            'prediction': prediction_list,            'prediction_time': prediction_time_str        })    # except Exception as e:    #     logger.error(f'Encountered an error: {e}', exc_info=True)    #     return jsonify({'error': str(e)}), 500    except ValueError as ve:        logger.error(f'Date-Time Parsing Error: {ve}')        return jsonify({'error': 'Date-Time Parsing Error', 'details': str(ve)}), 500    except Exception as e:        logger.error(f'General Error: {e}', exc_info=True)        return jsonify({'error': 'General Error', 'details': str(e)}), 500if __name__ == "__main__":    app.run(host='0.0.0.0', port=5000)